{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Na√Øve Bayes text classification\n",
    "# Reuters-21578 Text Categorization Collection Data Set\n",
    "<br>Data Link- http://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Necessary Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import chardet\n",
    "import os\n",
    "import re\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading all 22 sgm files of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"/home/rohan/CMI/SEM_2/DMML/Assignment_2/reuters21578/reut2-%03d.sgm\" % r for r in range(0, 22)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the SGML data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex codes to extract actual body from all the sgm files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=re.compile(r'<TEXT[\\S\\s]*?>[\\S\\s]*?</TEXT>') \n",
    "t1=re.compile(r'<TEXT>')\n",
    "t2=re.compile(r'<TEXT TYPE=\"UNPROC\">')\n",
    "t3=re.compile(r'<TEXT TYPE=\"BRIEF\">')\n",
    "p=re.compile(r'&#2;([\\S\\s]*?)&#3')\n",
    "q=re.compile(r'<BODY>([\\S\\s]*?)</BODY>')\n",
    "r=re.compile(r'<TITLE>([\\S\\s]*?)</TITLE>')\n",
    "s=re.compile(r'<TOPICS>([\\s\\S]*?)</TOPICS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body=[]  #Storing body parts as defined in the ReadME document of the data\n",
    "for j in range(len(files)):\n",
    "    f=open(files[j])\n",
    "    data=f.read()\n",
    "    n=t.findall(data)\n",
    "    for i in n:\n",
    "        if t1.findall(i)!=[]:\n",
    "            body=body+(q.findall(i))\n",
    "        elif t2.findall(i)!=[]:\n",
    "            body=body+(p.findall(i))\n",
    "        elif t3.findall(i)!=[]:\n",
    "            body=body+(r.findall(i))\n",
    "        \n",
    "len(body)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting topics from the sgm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic=[]  #storing all the topic names(None for no topic names)\n",
    "import re\n",
    "u=re.compile(r\"<TOPICS(>[<D>(\\S)</D>]*<)/TOPICS>\")\n",
    "v=re.compile(r\"<D>([\\w-]*)</D>\")\n",
    "for j in range(len(files)):\n",
    "    f=open(files[j])\n",
    "    data=f.read()\n",
    "    m = u.findall(data)\n",
    "    for x in m:\n",
    "        if x=='><':\n",
    "            topic.append([\"None\"])\n",
    "        else:\n",
    "            topic.append(v.findall(x))\n",
    "len(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting CGI Train/test split from the sgm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CGI=[]\n",
    "z=re.compile(r'CGISPLIT=(\\S+)')\n",
    "for  j in range(len(files)):\n",
    "    f=open(files[j])\n",
    "    data=f.read()\n",
    "    CGI+=z.findall(data)\n",
    "len(CGI)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting LEWIS Train/test split from the sgm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEWIS=[]\n",
    "z=re.compile(r'LEWISSPLIT=(\\S+)')\n",
    "for  j in range(len(files)):\n",
    "    f=open(files[j])\n",
    "    data=f.read()\n",
    "    LEWIS+=z.findall(data)\n",
    "len(LEWIS)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dataframe df consisting columns obtained from lists topics,body,CGI,LEWIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(list(zip(topic,body,CGI,LEWIS)),\n",
    "              columns=['topics','body','CGI','LEWIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>body</th>\n",
       "      <th>CGI</th>\n",
       "      <th>LEWIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cocoa]</td>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[None]</td>\n",
       "      <td>Standard Oil Co and BP North America\\nInc said...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[None]</td>\n",
       "      <td>Texas Commerce Bancshares Inc's Texas\\nCommerc...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[None]</td>\n",
       "      <td>BankAmerica Corp is not under\\npressure to act...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[grain, wheat, corn, barley, oat, sorghum]</td>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       topics  \\\n",
       "0                                     [cocoa]   \n",
       "1                                      [None]   \n",
       "2                                      [None]   \n",
       "3                                      [None]   \n",
       "4  [grain, wheat, corn, barley, oat, sorghum]   \n",
       "\n",
       "                                                body             CGI    LEWIS  \n",
       "0  Showers continued throughout the week in\\nthe ...  \"TRAINING-SET\"  \"TRAIN\"  \n",
       "1  Standard Oil Co and BP North America\\nInc said...  \"TRAINING-SET\"  \"TRAIN\"  \n",
       "2  Texas Commerce Bancshares Inc's Texas\\nCommerc...  \"TRAINING-SET\"  \"TRAIN\"  \n",
       "3  BankAmerica Corp is not under\\npressure to act...  \"TRAINING-SET\"  \"TRAIN\"  \n",
       "4  The U.S. Agriculture Department\\nreported the ...  \"TRAINING-SET\"  \"TRAIN\"  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the rows which have null values in the Topics column of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['topics'])):\n",
    "    if df['topics'][i]==['None']:\n",
    "        df['topics'][i]=None\n",
    "df = df.dropna(how='any',axis=0) \n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"TRAINING-SET\"', '\"PUBLISHED-TESTSET\"'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['\"TRAIN\"', '\"NOT-USED\"', '\"TEST\"'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CGI'].unique()\n",
    "df['LEWIS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new dataframe named same as the previous dataframe(df) <br>\n",
    "Here different topics in a list of 'topics' column in the old dataframe are separated in different rows in the new dataframe and body is repeated for each of them in the same list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_top=[]\n",
    "new_body=[]\n",
    "new_CGI=[]\n",
    "new_LEWIS=[]\n",
    "for i in range(len(topic)):\n",
    "    for j in topic[i]:\n",
    "        new_top.append(j)\n",
    "        new_body.append(body[i])\n",
    "        new_CGI.append(CGI[i])\n",
    "        new_LEWIS.append(LEWIS[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(list(zip(new_top,new_body,new_CGI,new_LEWIS)),\n",
    "              columns=['Topics','Body','CGI','LEWIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>Body</th>\n",
       "      <th>CGI</th>\n",
       "      <th>LEWIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cocoa</td>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Standard Oil Co and BP North America\\nInc said...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Texas Commerce Bancshares Inc's Texas\\nCommerc...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>BankAmerica Corp is not under\\npressure to act...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grain</td>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topics                                               Body             CGI  \\\n",
       "0  cocoa  Showers continued throughout the week in\\nthe ...  \"TRAINING-SET\"   \n",
       "1   None  Standard Oil Co and BP North America\\nInc said...  \"TRAINING-SET\"   \n",
       "2   None  Texas Commerce Bancshares Inc's Texas\\nCommerc...  \"TRAINING-SET\"   \n",
       "3   None  BankAmerica Corp is not under\\npressure to act...  \"TRAINING-SET\"   \n",
       "4  grain  The U.S. Agriculture Department\\nreported the ...  \"TRAINING-SET\"   \n",
       "\n",
       "     LEWIS  \n",
       "0  \"TRAIN\"  \n",
       "1  \"TRAIN\"  \n",
       "2  \"TRAIN\"  \n",
       "3  \"TRAIN\"  \n",
       "4  \"TRAIN\"  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(24513, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the rows which have null values in the Topics column of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14302, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df['Topics'])):\n",
    "    if df['Topics'][i]=='None':\n",
    "        df['Topics'][i]=None\n",
    "df= df.dropna(how='any',axis=0) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicate rows of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>Body</th>\n",
       "      <th>CGI</th>\n",
       "      <th>LEWIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cocoa</td>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grain</td>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veg-oil</td>\n",
       "      <td>Argentine grain board figures show\\ncrop regis...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn</td>\n",
       "      <td>Champion Products Inc said its\\nboard of direc...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acq</td>\n",
       "      <td>Computer Terminal Systems Inc said\\nit has com...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topics                                               Body             CGI  \\\n",
       "0    cocoa  Showers continued throughout the week in\\nthe ...  \"TRAINING-SET\"   \n",
       "1    grain  The U.S. Agriculture Department\\nreported the ...  \"TRAINING-SET\"   \n",
       "2  veg-oil  Argentine grain board figures show\\ncrop regis...  \"TRAINING-SET\"   \n",
       "3     earn  Champion Products Inc said its\\nboard of direc...  \"TRAINING-SET\"   \n",
       "4      acq  Computer Terminal Systems Inc said\\nit has com...  \"TRAINING-SET\"   \n",
       "\n",
       "     LEWIS  \n",
       "0  \"TRAIN\"  \n",
       "1  \"TRAIN\"  \n",
       "2  \"TRAIN\"  \n",
       "3  \"TRAIN\"  \n",
       "4  \"TRAIN\"  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11230, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset = \"Body\" ,inplace = True) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label encoding of Topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "df[\"Topic_code\"] = lb_make.fit_transform(df[\"Topics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>Body</th>\n",
       "      <th>CGI</th>\n",
       "      <th>LEWIS</th>\n",
       "      <th>Topic_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cocoa</td>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grain</td>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veg-oil</td>\n",
       "      <td>Argentine grain board figures show\\ncrop regis...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn</td>\n",
       "      <td>Champion Products Inc said its\\nboard of direc...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acq</td>\n",
       "      <td>Computer Terminal Systems Inc said\\nit has com...</td>\n",
       "      <td>\"TRAINING-SET\"</td>\n",
       "      <td>\"TRAIN\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topics                                               Body             CGI  \\\n",
       "0    cocoa  Showers continued throughout the week in\\nthe ...  \"TRAINING-SET\"   \n",
       "1    grain  The U.S. Agriculture Department\\nreported the ...  \"TRAINING-SET\"   \n",
       "2  veg-oil  Argentine grain board figures show\\ncrop regis...  \"TRAINING-SET\"   \n",
       "3     earn  Champion Products Inc said its\\nboard of direc...  \"TRAINING-SET\"   \n",
       "4      acq  Computer Terminal Systems Inc said\\nit has com...  \"TRAINING-SET\"   \n",
       "\n",
       "     LEWIS  Topic_code  \n",
       "0  \"TRAIN\"           6  \n",
       "1  \"TRAIN\"          24  \n",
       "2  \"TRAIN\"          76  \n",
       "3  \"TRAIN\"          17  \n",
       "4  \"TRAIN\"           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split for Body and Topic-code of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (11230,)\n",
      "Shape of X_train is (8422,) and shape of y_train is (8422,)\n",
      "Shape of X_test is (2808,) and shape of y_test is (2808,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Body']\n",
    "y = df['Topic_code']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "\n",
    "print(\"Shape of X is {}\".format(X.shape))\n",
    "print(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...      vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6456552706552706"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model= MultinomialNB()\n",
    "pipeline_Mnv = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('classifier', model)])\n",
    "\n",
    "pipeline_Mnv.fit(X_train, y_train)\n",
    "y_predicted_Mnv = pipeline_Mnv.predict(X_test)\n",
    "accuracy_Mnv = accuracy_score(y_test, y_predicted_Mnv)\n",
    "#precision, recall, f1_score, _ = precision_recall_fscore_support(y_te,y_predicted_BNB)\n",
    "accuracy_Mnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[633,  10,   1, ...,   2,   0,   3],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_predicted_Mnv,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Complement Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...ulary=None)), ('classifier', ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8190883190883191"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "model = ComplementNB()\n",
    "\n",
    "pipeline_Cnv = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('classifier', model)])\n",
    "\n",
    "pipeline_Cnv.fit(X_train, y_train)\n",
    "y_predicted_Cnv= pipeline_Cnv.predict(X_test)\n",
    "accuracy_Cnv = accuracy_score(y_test, y_predicted_Cnv)\n",
    "accuracy_Cnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[630,   5,   0, ...,   0,   0,   2],\n",
       "       [  0,   8,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   1,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predicted_Cnv,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of train and test data (CGISPLIT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainC=df.loc[df['CGI'] == '\"TRAINING-SET\"']\n",
    "df_testC=df.loc[df['CGI'] == '\"PUBLISHED-TESTSET\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trC=df_trainC['Body']\n",
    "y_trC=df_trainC['Topic_code']\n",
    "X_teC=df_testC['Body']\n",
    "y_teC=df_testC['Topic_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Multinomial Naive Bayes Model (CGISPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...      vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.32299270072992703"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model= MultinomialNB()\n",
    "pipeline_Mnv = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('classifier', model)])\n",
    "\n",
    "pipeline_Mnv.fit(X_trC, y_trC)\n",
    "y_predicted_Mnv = pipeline_Mnv.predict(X_teC)\n",
    "accuracy_Mnv = accuracy_score(y_teC, y_predicted_Mnv)\n",
    "#precision, recall, f1_score, _ = precision_recall_fscore_support(y_te,y_predicted_BNB)\n",
    "accuracy_Mnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74,  2,  1, ...,  9,  0,  3],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predicted_Mnv,y_teC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Complement Naive Bayes Model (CGISPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...ulary=None)), ('classifier', ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6459854014598541"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "model = ComplementNB()\n",
    "\n",
    "pipeline_Cnv = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('classifier', model)])\n",
    "\n",
    "pipeline_Cnv.fit(X_trC, y_trC)\n",
    "y_predicted_Cnv= pipeline_Cnv.predict(X_teC)\n",
    "accuracy_Cnv = accuracy_score(y_teC, y_predicted_Cnv)\n",
    "accuracy_Cnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75,  0,  0, ...,  0,  0,  2],\n",
       "       [ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  2,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predicted_Cnv,y_teC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of train and test data (LEWISSPLIT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainL=df.loc[df['LEWIS'] == '\"TRAIN\"']\n",
    "df_testL=df.loc[df['LEWIS'] == '\"TEST\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trL=df_trainL['Body']\n",
    "y_trL=df_trainL['Topic_code']\n",
    "X_teL=df_testL['Body']\n",
    "y_teL=df_testL['Topic_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Multinomial Naive Bayes Model (LEWISSPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...      vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.643023643023643"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= MultinomialNB()\n",
    "pipeline_Mnv = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('classifier', model)])\n",
    "\n",
    "pipeline_Mnv.fit(X_trL, y_trL)\n",
    "y_predicted_Mnv = pipeline_Mnv.predict(X_teL)\n",
    "accuracy_Mnv = accuracy_score(y_teL, y_predicted_Mnv)\n",
    "#precision, recall, f1_score, _ = precision_recall_fscore_support(y_te,y_predicted_BNB)\n",
    "accuracy_Mnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[692,   9,   1, ...,   0,   2,   5],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predicted_Mnv,y_teL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Complement Naive Bayes Model (LEWISSPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...ulary=None)), ('classifier', ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8191808191808192"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "\n",
    "pipeline_Cnv = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('classifier', model)])\n",
    "\n",
    "pipeline_Cnv.fit(X_trL, y_trL)\n",
    "y_predicted_Cnv= pipeline_Cnv.predict(X_teL)\n",
    "accuracy_Cnv = accuracy_score(y_teL, y_predicted_Cnv)\n",
    "accuracy_Cnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[701,   5,   0, ...,   0,   0,   1],\n",
       "       [  0,   8,   0, ...,   0,   0,   2],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   1,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predicted_Cnv,y_teL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label Classification using train-test split from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['Topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\b[^\\\\d\\\\W]+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( df['Body'] , y , random_state = 52)\n",
    "\n",
    "tfidf_transformer = TfidfVectorizer(token_pattern = r'\\b[^\\d\\W]+\\b')\n",
    "tfidf_transformer.fit(X_train)\n",
    "X_train_tfidf=tfidf_transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Complement Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LabelPowerset(ComplementNB())\n",
    "classifier.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf=tfidf_transformer.transform(X_test)\n",
    "pred = classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8379629629629629\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445868945868946\n"
     ]
    }
   ],
   "source": [
    "classifier = LabelPowerset(MultinomialNB())\n",
    "classifier.fit(X_train_tfidf,y_train)\n",
    "X_test_tfidf=tfidf_transformer.transform(X_test)\n",
    "pred = classifier.predict(X_test_tfidf)\n",
    "print(accuracy_score(y_test,pred.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Classification using CGISPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teC_t= mlb.fit_transform(df.loc[df['CGI'] == '\"PUBLISHED-TESTSET\"']['Topics'])\n",
    "y_trC_t= mlb.fit_transform(df.loc[df['CGI'] == '\"TRAINING-SET\"']['Topics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\b[^\\\\d\\\\W]+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.fit(X_trC)\n",
    "X_train_tfidf=tfidf_transformer.transform(X_trC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10682, 25967)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10682, 27)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape\n",
    "y_trC_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33211678832116787\n"
     ]
    }
   ],
   "source": [
    "classifier = LabelPowerset(MultinomialNB())\n",
    "classifier.fit(X_train_tfidf,y_trC_t)\n",
    "X_test_tfidf=tfidf_transformer.transform(X_teC)\n",
    "pred = classifier.predict(X_test_tfidf)\n",
    "print(accuracy_score(y_teC_t,pred.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Complement Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6642335766423357\n"
     ]
    }
   ],
   "source": [
    "classifier = LabelPowerset(ComplementNB())\n",
    "classifier.fit(X_train_tfidf,y_trC_t)\n",
    "X_test_tfidf=tfidf_transformer.transform(X_teC)\n",
    "pred = classifier.predict(X_test_tfidf)\n",
    "print(accuracy_score(y_teC_t,pred.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-level Classification using LEWISSPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teL_t= mlb.fit_transform(df.loc[df['LEWIS'] == '\"TEST\"']['Topics'])\n",
    "y_trL_t= mlb.fit_transform(df.loc[df['LEWIS'] == '\"TRAIN\"']['Topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\b[^\\\\d\\\\W]+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.fit(X_trL)\n",
    "X_train_tfidf=tfidf_transformer.transform(X_trL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7679, 22133)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7679, 27)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape\n",
    "y_trL_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655011655011655\n"
     ]
    }
   ],
   "source": [
    "classifier = LabelPowerset(MultinomialNB())\n",
    "classifier.fit(X_train_tfidf,y_trL_t)\n",
    "\n",
    "X_test_tfidf=tfidf_transformer.transform(X_teL)\n",
    "pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(accuracy_score(y_teL_t,pred.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Complement Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8334998334998335\n"
     ]
    }
   ],
   "source": [
    "classifier = LabelPowerset(ComplementNB())\n",
    "classifier.fit(X_train_tfidf,y_trL_t)\n",
    "X_test_tfidf=tfidf_transformer.transform(X_teL)\n",
    "pred = classifier.predict(X_test_tfidf)\n",
    "print(accuracy_score(y_teL_t,pred.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
